# Generated by Honegumi (https://arxiv.org/abs/2502.06815)
# %pip install ax-platform==0.4.3 matplotlib
import numpy as np
import pandas as pd
from ax.service.ax_client import AxClient, ObjectiveProperties
import matplotlib.pyplot as plt


obj1_name = "branin"
obj2_name = "branin_swapped"


def branin_moo(x1, x2):
    y = float(
        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2
        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)
        + 10
    )

    # second objective has x1 and x2 swapped
    y2 = float(
        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2
        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)
        + 10
    )

    return {obj1_name: y, obj2_name: y2}


ax_client = AxClient()

ax_client.create_experiment(
    parameters=[
        {"name": "x1", "type": "range", "bounds": [-5.0, 10.0]},
        {"name": "x2", "type": "range", "bounds": [0.0, 10.0]},
    ],
    objectives={
        obj1_name: ObjectiveProperties(minimize=True),
        obj2_name: ObjectiveProperties(minimize=True),
    },
)


for i in range(19):

    parameterization, trial_index = ax_client.get_next_trial()

    # extract parameters
    x1 = parameterization["x1"]
    x2 = parameterization["x2"]

    results = branin_moo(x1, x2)
    ax_client.complete_trial(trial_index=trial_index, raw_data=results)
pareto_results = ax_client.get_pareto_optimal_parameters()


# Plot results
objectives = ax_client.objective_names
df = ax_client.get_trials_data_frame()

fig, ax = plt.subplots(figsize=(6, 4), dpi=150)
pareto = ax_client.get_pareto_optimal_parameters(use_model_predictions=False)
pareto_data = [p[1][0] for p in pareto.values()]
pareto = pd.DataFrame(pareto_data).sort_values(objectives[0])

ax.scatter(df[objectives[0]], df[objectives[1]], fc="None", ec="k", label="Observed")
ax.plot(
    pareto[objectives[0]],
    pareto[objectives[1]],
    color="#0033FF",
    lw=2,
    label="Pareto Front",
)
ax.set_xlabel(objectives[0])
ax.set_ylabel(objectives[1])

ax.legend()
plt.show()

# Generated for Protein Bar Multi-Objective Optimization with Ax Platform
# %pip install ax-platform==0.4.3 matplotlib
import numpy as np
import pandas as pd
from ax.service.ax_client import AxClient, ObjectiveProperties
import matplotlib.pyplot as plt


# Objective metric names
texture_metric = "texture_rating"
taste_metric = "taste_rating"


def evaluate_protein_bar(protein_pct: float, sweetener_pct: float, binder_pct: float, flavor_pct: float) -> dict:
    """
    Simulated evaluation of a protein bar formulation.
    Objectives:
      - texture_rating (1-10): Mouthfeel, chewiness, cohesiveness.
      - taste_rating (1-10): Sweetness balance, flavor intensity, absence of off-notes.

    This function provides a realistic, smooth, and noisy proxy model with
    interaction effects and diminishing returns. Replace with actual measurements
    when running real kitchen or pilot-plant trials (e.g., panel averages).
    """
    # Utility helpers
    def gauss(x, mu, sigma):
        return np.exp(-0.5 * ((x - mu) / sigma) ** 2)

    def clamp(v, lo=1.0, hi=10.0):
        return float(max(lo, min(hi, v)))

    # Normalize some intuitive centers and spreads (all in absolute % units)
    # Texture: best with moderate protein (30%), adequate binder (18%),
    # modest sweetener (9%), balanced flavor (4%).
    texture_pref = (
        0.45 * gauss(protein_pct, 30.0, 6.0)
        + 0.40 * gauss(binder_pct, 18.0, 4.0)
        + 0.10 * gauss(sweetener_pct, 9.0, 3.0)
        + 0.05 * gauss(flavor_pct, 4.0, 2.0)
    )

    # Texture penalties: high sweetener can make stickiness/softness; very high protein can be crumbly
    texture_penalty = 0.0
    if sweetener_pct > 13.0:
        texture_penalty += 0.10 * ((sweetener_pct - 13.0) / 2.0) ** 2
    if protein_pct > 38.0:
        texture_penalty += 0.12 * ((protein_pct - 38.0) / 3.0) ** 2
    if binder_pct < 12.0:
        texture_penalty += 0.08 * ((12.0 - binder_pct) / 2.0) ** 2

    texture_score = texture_pref - texture_penalty
    texture_rating = 1.0 + 9.0 * max(0.0, min(1.0, texture_score))

    # Taste: best with sweetener around 11.5%, flavor around 6%,
    # modest binder influence, protein too high can mute taste.
    taste_pref = (
        0.45 * gauss(sweetener_pct, 11.5, 2.2)
        + 0.35 * gauss(flavor_pct, 6.0, 1.2)
        + 0.10 * gauss(binder_pct, 14.0, 4.0)
        + 0.10 * gauss(protein_pct, 26.0, 6.0)
    )

    # Synergy between sweetener and flavor near their sweet spots
    synergy = 0.08 * gauss(sweetener_pct + flavor_pct, 17.5, 2.5)

    # Penalties: too much flavor or sweetener can be cloying; high protein chalkiness
    taste_penalty = 0.0
    if sweetener_pct > 13.5:
        taste_penalty += 0.10 * ((sweetener_pct - 13.5) / 2.0) ** 2
    if flavor_pct > 7.0:
        taste_penalty += 0.10 * ((flavor_pct - 7.0) / 1.0) ** 2
    if protein_pct > 34.0:
        taste_penalty += 0.10 * ((protein_pct - 34.0) / 4.0) ** 2

    taste_score = taste_pref + synergy - taste_penalty
    taste_rating = 1.0 + 9.0 * max(0.0, min(1.0, taste_score))

    # Add realistic measurement noise (panel variability, batch-to-batch variation)
    noise_sd = 0.2  # approx. +/- 0.2 rating points
    # Use a module-level RNG for reproducibility across runs while remaining stochastic across trials
    noise_tex = rng.normal(0.0, noise_sd)
    noise_taste = rng.normal(0.0, noise_sd)

    texture_rating = clamp(texture_rating + noise_tex)
    taste_rating = clamp(taste_rating + noise_taste)

    return {
        texture_metric: texture_rating,
        taste_metric: taste_rating,
    }


# Reproducible RNG for simulated noise
rng = np.random.default_rng(2025)

# Set up Ax optimization client
ax_client = AxClient()

# Create multi-objective experiment for protein bar formulation
ax_client.create_experiment(
    name="protein_bar_dual_objective_optimization",
    parameters=[
        {"name": "protein_pct", "type": "range", "bounds": [20.0, 40.0], "value_type": "float"},
        {"name": "sweetener_pct", "type": "range", "bounds": [5.0, 15.0], "value_type": "float"},
        {"name": "binder_pct", "type": "range", "bounds": [10.0, 25.0], "value_type": "float"},
        {"name": "flavor_pct", "type": "range", "bounds": [2.0, 8.0], "value_type": "float"},
    ],
    objectives={
        texture_metric: ObjectiveProperties(minimize=False),
        taste_metric: ObjectiveProperties(minimize=False),
    },
)

# Run optimization within the 35-batch budget
num_trials = 35
for _ in range(num_trials):
    parameterization, trial_index = ax_client.get_next_trial()

    # Extract current formulation parameters
    protein = parameterization["protein_pct"]
    sweetener = parameterization["sweetener_pct"]
    binder = parameterization["binder_pct"]
    flavor = parameterization["flavor_pct"]

    # Evaluate the formulation (simulated here; replace with real measurements when available)
    results = evaluate_protein_bar(protein, sweetener, binder, flavor)

    # Report results back to Ax
    ax_client.complete_trial(trial_index=trial_index, raw_data=results)

# Retrieve Pareto-optimal formulations according to observed data
pareto_params = ax_client.get_pareto_optimal_parameters(use_model_predictions=False)

# Plot observed outcomes and Pareto front
objective_names = ax_client.objective_names
df = ax_client.get_trials_data_frame()

fig, ax = plt.subplots(figsize=(7, 5), dpi=150)
ax.scatter(
    df[objective_names[0]], df[objective_names[1]], fc="None", ec="k", label="Observed batches"
)

# Extract Pareto frontier in objective space for plotting
pareto_obs = [p[1][0] for p in pareto_params.values()]  # metric means dict per Pareto arm
pareto_df = pd.DataFrame(pareto_obs).sort_values(objective_names[0])

ax.plot(
    pareto_df[objective_names[0]],
    pareto_df[objective_names[1]],
    color="#0033FF",
    lw=2,
    label="Observed Pareto Front",
)

ax.set_xlabel(f"{objective_names[0]} (1-10)")
ax.set_ylabel(f"{objective_names[1]} (1-10)")
ax.set_title("Protein Bar Optimization: Texture vs. Taste")
ax.legend()
plt.tight_layout()
plt.show()