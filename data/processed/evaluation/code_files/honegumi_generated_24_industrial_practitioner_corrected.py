# Generated by Honegumi (https://arxiv.org/abs/2502.06815)
# %pip install ax-platform==0.4.3 matplotlib
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from typing import Dict, Tuple
from ax.service.ax_client import AxClient, ObjectiveProperties


# Seed for reproducibility of the noise model
rng = np.random.default_rng(seed=42)

# Problem: Ink formulation optimization with composition constraint
# Components (percent by weight): silver, solvent, binder, additive
# Objectives: maximize conductivity (S/m), maximize printability (1-10)
# Constraint: silver + solvent + binder + additive == 100%
# Bounds:
#   silver:   [40, 70] %
#   solvent:  [15, 35] %
#   binder:   [ 5, 20] %
#   additive: [ 2, 10] %


# Objective names
conductivity_metric = "conductivity_S_per_m"
printability_metric = "printability_score"

# Total composition percentage
total_percentage = 100.0


def evaluate_ink_formulation(
    silver_pct: float,
    solvent_pct: float,
    binder_pct: float,
    additive_pct: float,
) -> Dict[str, float]:
    """
    Simulated evaluation of ink formulation.

    This function emulates plausible physical behavior for:
      - Electrical conductivity: driven primarily by silver loading and microstructure.
      - Printability score (1-10): driven by rheology and surface properties; tends to peak at balanced formulations.

    NOTE: Replace this simulation with real measurements from lab experiments or a high-fidelity simulator.
    Integration points could include:
      - Instrument control and data acquisition
      - Database lookup of prior batches
      - Physics-based sintering and rheology models

    Returns:
      Dict with keys:
        - "conductivity_S_per_m": float
        - "printability_score": float
    """
    # Convert to fractions for modeling convenience
    s = silver_pct / 100.0
    v = solvent_pct / 100.0
    b = binder_pct / 100.0
    a = additive_pct / 100.0

    # Conductivity model (S/m):
    # Percolation-like behavior with threshold on silver content, penalized by solvent and binder,
    # and slight boost from functional additives.
    # Baseline cap for achievable effective conductivity (far below bulk silver).
    percolation_threshold = 0.50
    if s <= percolation_threshold:
        sigma = 5.0  # near-insulating regime (very low, but > 0)
    else:
        # Normalized distance above percolation
        phi = (s - percolation_threshold) / (1.0 - percolation_threshold)
        # Base effective conductivity level (cap around 1e6 S/m for printed/sintered inks)
        sigma_base = 1.0e6 * (phi**2.0)

        # Penalize high solvent and binder fractions (porosity, barriers to sintering)
        penalty_solvent = np.exp(-3.0 * v)
        penalty_binder = np.exp(-2.0 * b)

        # Additive can slightly aid sintering/networking
        additive_boost = 1.0 + 0.4 * a

        sigma = sigma_base * penalty_solvent * penalty_binder * additive_boost
        sigma = float(max(sigma, 1.0))  # ensure positive floor

    # Add multiplicative noise to conductivity to emulate measurement variability
    sigma *= float(rng.lognormal(mean=0.0, sigma=0.06))

    # Printability model (1-10):
    # Target region for balanced formulations (empirical "sweet spot").
    # Peaks near: silver ~55%, solvent ~28%, binder ~12%, additive ~5%
    # Gaussian-like preference around that point with broader tolerance on silver/solvent, narrower on binder/additive.
    center = {
        "silver": 55.0,
        "solvent": 28.0,
        "binder": 12.0,
        "additive": 5.0,
    }
    scales = {
        "silver": 10.0,   # broader tolerance
        "solvent": 7.0,
        "binder": 4.0,    # tighter tolerance
        "additive": 2.0,  # tightest tolerance
    }

    d2 = (
        ((silver_pct - center["silver"]) / scales["silver"]) ** 2.0
        + ((solvent_pct - center["solvent"]) / scales["solvent"]) ** 2.0
        + ((binder_pct - center["binder"]) / scales["binder"]) ** 2.0
        + ((additive_pct - center["additive"]) / scales["additive"]) ** 2.0
    )
    base_score = 1.0 + 9.0 * np.exp(-0.5 * d2)

    # Additional penalties for extremes: very high silver (> 65%) can reduce jetting quality,
    # very low solvent (< 18%) may reduce flow, very high binder (> 18%) may clog nozzles.
    penalty = 0.0
    if silver_pct > 65.0:
        penalty += 0.25 * (silver_pct - 65.0)
    if solvent_pct < 18.0:
        penalty += 0.3 * (18.0 - solvent_pct)
    if binder_pct > 18.0:
        penalty += 0.4 * (binder_pct - 18.0)

    printability = float(base_score - penalty)
    # Additive white Gaussian noise (score is bounded later)
    printability += float(rng.normal(loc=0.0, scale=0.15))
    # Clamp to [1, 10]
    printability = float(np.clip(printability, 1.0, 10.0))

    return {
        conductivity_metric: float(sigma),
        printability_metric: float(printability),
    }


def derive_additive(silver_pct: float, solvent_pct: float, binder_pct: float) -> float:
    """
    Given the three free components, derive additive percentage to enforce compositional equality:
      additive = 100 - (silver + solvent + binder)

    The search space constraints ensure additive remains within [2, 10]%.
    """
    return float(total_percentage - (silver_pct + solvent_pct + binder_pct))


def is_additive_within_bounds(additive_pct: float) -> bool:
    return 2.0 <= additive_pct <= 10.0


def compute_pareto_mask(points: np.ndarray) -> np.ndarray:
    """
    Compute Pareto-efficient mask for a set of points to be maximized.
    points: array of shape (n, m) with m objectives (here m=2).
    Returns: boolean mask indicating non-dominated points.
    """
    n = points.shape[0]
    mask = np.ones(n, dtype=bool)
    for i in range(n):
        if not mask[i]:
            continue
        # Any point that is strictly dominated by point i should be masked out
        dominates = np.all(points[i] >= points, axis=1) & np.any(points[i] > points, axis=1)
        # But don't compare a point to itself
        dominates[i] = False
        mask = mask & (~dominates)
    return mask


# Initialize Ax client and define experiment
ax_client = AxClient()

ax_client.create_experiment(
    name="ink_formulation_multiobjective",
    parameters=[
        # Three free variables; additive is derived to enforce sum to 100%.
        {"name": "silver_pct", "type": "range", "bounds": [40.0, 70.0]},
        {"name": "solvent_pct", "type": "range", "bounds": [15.0, 35.0]},
        {"name": "binder_pct", "type": "range", "bounds": [5.0, 20.0]},
    ],
    objectives={
        conductivity_metric: ObjectiveProperties(minimize=False),
        printability_metric: ObjectiveProperties(minimize=False),
    },
    parameter_constraints=[
        # Enforce additive bounds via inequalities on the sum of free variables:
        # additive = 100 - (silver + solvent + binder) in [2, 10]
        # => silver + solvent + binder in [90, 98]
        "silver_pct + solvent_pct + binder_pct <= 98.0",
        "silver_pct + solvent_pct + binder_pct >= 90.0",
    ],
    overwrite_existing_experiment=True,
)


# Optimization loop: 45 trials (batches)
num_trials = 45
for _ in range(num_trials):
    params, trial_index = ax_client.get_next_trial()

    silver_pct = float(params["silver_pct"])
    solvent_pct = float(params["solvent_pct"])
    binder_pct = float(params["binder_pct"])
    additive_pct = derive_additive(silver_pct, solvent_pct, binder_pct)

    # Safety check (should always pass due to constraints)
    if not is_additive_within_bounds(additive_pct):
        # Mark as failed trial with extremely poor outcomes to discourage infeasible regions
        # (Should not occur given constraints; this is defensive programming.)
        ax_client.complete_trial(
            trial_index=trial_index,
            raw_data={
                conductivity_metric: 0.0,
                printability_metric: 1.0,
            },
        )
        continue

    results = evaluate_ink_formulation(silver_pct, solvent_pct, binder_pct, additive_pct)
    ax_client.complete_trial(trial_index=trial_index, raw_data=results)

# Retrieve observed data frame
df = ax_client.get_trials_data_frame()

# Identify objective columns (should match our metric names)
metric_cols = [col for col in df.columns if col in {conductivity_metric, printability_metric}]
if len(metric_cols) != 2:
    raise RuntimeError("Expected to find both objective columns in the trials DataFrame.")

# Compute Pareto front from observed data
points = df[[conductivity_metric, printability_metric]].to_numpy(dtype=float)
pareto_mask = compute_pareto_mask(points)
pareto_df = df.loc[pareto_mask, [conductivity_metric, printability_metric]].copy()
pareto_df.sort_values(by=conductivity_metric, inplace=True)

# Plot observed points and Pareto frontier
fig, ax = plt.subplots(figsize=(7, 5), dpi=150)
ax.scatter(
    df[conductivity_metric],
    df[printability_metric],
    fc="None",
    ec="k",
    label="Observed",
)

ax.plot(
    pareto_df[conductivity_metric],
    pareto_df[printability_metric],
    color="#0033FF",
    lw=2,
    label="Pareto Front (Observed)",
)

ax.set_xlabel("Conductivity (S/m)")
ax.set_ylabel("Printability (1-10)")
ax.set_title("Ink Formulation: Conductivity vs. Printability")
ax.legend()
plt.tight_layout()
plt.show()