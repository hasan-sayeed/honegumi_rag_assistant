# Generated by Honegumi (https://arxiv.org/abs/2502.06815)
# %pip install ax-platform==0.4.3 matplotlib
import numpy as np
import pandas as pd
from ax.service.ax_client import AxClient, ObjectiveProperties
import matplotlib.pyplot as plt


obj1_name = "branin"
obj2_name = "branin_swapped"


def branin_moo(x1, x2):
    y = float(
        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2
        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)
        + 10
    )

    # second objective has x1 and x2 swapped
    y2 = float(
        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2
        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)
        + 10
    )

    return {obj1_name: y, obj2_name: y2}


ax_client = AxClient()

ax_client.create_experiment(
    parameters=[
        {"name": "x1", "type": "range", "bounds": [-5.0, 10.0]},
        {"name": "x2", "type": "range", "bounds": [0.0, 10.0]},
    ],
    objectives={
        obj1_name: ObjectiveProperties(minimize=True),
        obj2_name: ObjectiveProperties(minimize=True),
    },
)


for i in range(19):

    parameterization, trial_index = ax_client.get_next_trial()

    # extract parameters
    x1 = parameterization["x1"]
    x2 = parameterization["x2"]

    results = branin_moo(x1, x2)
    ax_client.complete_trial(trial_index=trial_index, raw_data=results)
pareto_results = ax_client.get_pareto_optimal_parameters()


# Plot results
objectives = ax_client.objective_names
df = ax_client.get_trials_data_frame()

fig, ax = plt.subplots(figsize=(6, 4), dpi=150)
pareto = ax_client.get_pareto_optimal_parameters(use_model_predictions=False)
pareto_data = [p[1][0] for p in pareto.values()]
pareto = pd.DataFrame(pareto_data).sort_values(objectives[0])

ax.scatter(df[objectives[0]], df[objectives[1]], fc="None", ec="k", label="Observed")
ax.plot(
    pareto[objectives[0]],
    pareto[objectives[1]],
    color="#0033FF",
    lw=2,
    label="Pareto Front",
)
ax.set_xlabel(objectives[0])
ax.set_ylabel(objectives[1])

ax.legend()
plt.show()

# Multi-objective Bayesian optimization for drug discovery using Ax Platform
# %pip install ax-platform==0.4.3 matplotlib
import math
import random
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from typing import Dict, Tuple

from ax.service.ax_client import AxClient
from ax.service.utils.instantiation import ObjectiveProperties


# ----------------------------
# Domain-specific configuration
# ----------------------------
# Parameters (molecular descriptors):
# - MW: Molecular weight in Daltons [180, 500]
# - LogP: Octanol/water partition coefficient (unitless) [0, 5]
# - TPSA: Topological polar surface area in Ã…^2 [20, 140]
# - HBD: Hydrogen bond donors (count) [0, 5]
# - HBA: Hydrogen bond acceptors (count) [0, 10]
#
# Objectives:
# - binding_affinity_pKi: maximize (unitless)
# - solubility_logS: maximize (unitless)
# - toxicity_LD50: minimize (mg/kg)  [Note: In practice, higher LD50 indicates lower toxicity.
#   If you prefer to optimize for safety, consider maximizing LD50 or minimizing 1/LD50.]
#
# Budget: 50 evaluations, with observation noise.


RNG_SEED = 42
random.seed(RNG_SEED)
np.random.seed(RNG_SEED)


# ----------------------------
# Surrogate evaluation function
# ----------------------------
def _gaussian_peak(x: float, mu: float, sigma: float) -> float:
    if sigma <= 0:
        return 0.0
    z = (x - mu) / sigma
    return float(math.exp(-0.5 * z * z))


def _sigmoid(x: float) -> float:
    return float(1.0 / (1.0 + math.exp(-x)))


def evaluate_molecule(parameterization: Dict[str, float]) -> Dict[str, float]:
    """
    Evaluate the molecule defined by molecular descriptors.

    This function provides a realistic surrogate (QSAR-like) mapping from descriptors
    to three outcomes with added noise. Replace the surrogate with actual computation
    (e.g., docking for pKi, solubility prediction, and toxicity model) when available.

    Inputs:
        parameterization: dict with keys "MW", "LogP", "TPSA", "HBD", "HBA".

    Returns:
        dict mapping objective name to a single mean value (Ax will infer noise).
        {
            "binding_affinity_pKi": float,   # higher is better
            "solubility_logS": float,        # higher is better
            "toxicity_LD50": float,          # lower is better per problem statement
        }
    """
    mw = float(parameterization["MW"])
    logp = float(parameterization["LogP"])
    tpsa = float(parameterization["TPSA"])
    hbd = float(parameterization["HBD"])
    hba = float(parameterization["HBA"])

    # Binding affinity surrogate (pKi):
    # Favor moderate MW, moderate LogP, mid TPSA, and reasonable HBD/HBA.
    pki_base = 5.0
    pki = (
        pki_base
        + 1.2 * _gaussian_peak(mw, 350.0, 80.0)
        + 1.6 * _gaussian_peak(logp, 2.2, 1.0)
        + 1.2 * _gaussian_peak(tpsa, 70.0, 25.0)
        + 0.8 * _gaussian_peak(hbd, 1.5, 1.0)
        + 0.6 * _gaussian_peak(hba, 4.0, 2.0)
    )
    # Mild interaction: favor moderate MW and LogP together
    pki += 0.5 * _gaussian_peak((mw - 320.0) / 200.0 + (logp - 2.0), 0.0, 1.2)
    # Add noise
    pki += np.random.normal(0.0, 0.15)
    pki = float(np.clip(pki, 3.0, 12.0))

    # Solubility surrogate (logS):
    # Decreases with LogP and MW, increases with TPSA and HBD/HBA.
    logS = (
        0.7
        - 0.95 * logp
        - 0.0025 * (mw - 180.0)
        + 0.015 * (tpsa - 20.0)
        + 0.08 * hbd
        + 0.04 * hba
    )
    logS += np.random.normal(0.0, 0.12)
    logS = float(np.clip(logS, -12.0, 2.5))

    # Toxicity surrogate (LD50 mg/kg):
    # Higher LogP and MW tend to reduce LD50 (more toxic), while higher TPSA / HBD / HBA increase LD50 (less toxic).
    # We generate LD50 in ~[50, 2000] mg/kg with noise.
    risk_score = (
        0.6 * _sigmoid((logp - 2.5) / 0.8)
        + 0.35 * _sigmoid((mw - 400.0) / 50.0)
        - 0.35 * _sigmoid((tpsa - 70.0) / 15.0)
        - 0.2 * _sigmoid((hbd - 2.0) / 1.2)
        - 0.2 * _sigmoid((hba - 5.0) / 1.5)
    )
    # Convert risk into LD50 (higher risk -> lower LD50)
    ld50_center = 1100.0
    ld50 = ld50_center * np.clip(1.1 - 0.8 * risk_score, 0.05, 1.8)
    ld50 += np.random.normal(0.0, 50.0)
    ld50 = float(np.clip(ld50, 25.0, 2500.0))

    return {
        "binding_affinity_pKi": pki,
        "solubility_logS": logS,
        "toxicity_LD50": ld50,
    }


# ---------------------------------
# Pareto dominance utility functions
# ---------------------------------
def _dominates(a: Dict[str, float], b: Dict[str, float], sense: Dict[str, str]) -> bool:
    """Return True if point a Pareto-dominates point b for given senses.
    sense: dict metric -> "max" or "min"
    """
    better_or_equal_all = True
    strictly_better_any = False
    for m, s in sense.items():
        if s == "max":
            if a[m] < b[m]:
                better_or_equal_all = False
                break
            if a[m] > b[m]:
                strictly_better_any = True
        else:  # "min"
            if a[m] > b[m]:
                better_or_equal_all = False
                break
            if a[m] < b[m]:
                strictly_better_any = True
    return better_or_equal_all and strictly_better_any


def compute_pareto_indices(df_wide: pd.DataFrame, senses: Dict[str, str]) -> np.ndarray:
    """Compute indices of Pareto-optimal rows in a wide DataFrame with metric columns."""
    values = df_wide[list(senses.keys())].to_dict(orient="records")
    is_dominated = np.zeros(len(values), dtype=bool)
    for i, vi in enumerate(values):
        if is_dominated[i]:
            continue
        for j, vj in enumerate(values):
            if i == j or is_dominated[i]:
                continue
            if _dominates(vj, vi, senses):
                is_dominated[i] = True
    return np.where(~is_dominated)[0]


# ----------------------------
# Ax experiment configuration
# ----------------------------
ax_client = AxClient(random_seed=RNG_SEED)

ax_client.create_experiment(
    name="drug_discovery_moo",
    parameters=[
        {"name": "MW", "type": "range", "bounds": [180.0, 500.0]},
        {"name": "LogP", "type": "range", "bounds": [0.0, 5.0]},
        {"name": "TPSA", "type": "range", "bounds": [20.0, 140.0]},
        {"name": "HBD", "type": "range", "bounds": [0.0, 5.0]},
        {"name": "HBA", "type": "range", "bounds": [0.0, 10.0]},
    ],
    objectives={
        "binding_affinity_pKi": ObjectiveProperties(minimize=False),
        "solubility_logS": ObjectiveProperties(minimize=False),
        "toxicity_LD50": ObjectiveProperties(minimize=True),
    },
    overwrite_existing_experiment=True,
    is_test=True,
)

# ----------------------------
# Optimization loop (50 trials)
# ----------------------------
N_TRIALS = 50

for _ in range(N_TRIALS):
    params, trial_index = ax_client.get_next_trial()
    results = evaluate_molecule(params)
    # Pass means only; set sem=None to let Ax infer noise internally
    ax_client.complete_trial(trial_index=trial_index, raw_data=results)

# ----------------------------
# Retrieve and visualize results
# ----------------------------
# Build a wide DataFrame with one row per trial and columns for each metric.
df = ax_client.get_trials_data_frame()

# Pivot to wide format: index by trial_index (each trial in AxClient is single-arm)
df_wide = (
    df.pivot_table(index="trial_index", columns="metric_name", values="mean", aggfunc="last")
    .reset_index()
    .sort_values("trial_index")
)

# Keep only our metrics in the desired order
metric_order = ["binding_affinity_pKi", "solubility_logS", "toxicity_LD50"]
df_wide = df_wide[["trial_index"] + metric_order].dropna()

# Compute Pareto set (observed)
senses = {
    "binding_affinity_pKi": "max",
    "solubility_logS": "max",
    "toxicity_LD50": "min",
}
pareto_idx_local = compute_pareto_indices(df_wide[metric_order], senses)
pareto_trials = df_wide.iloc[pareto_idx_local]["trial_index"].tolist()

print(f"Completed {len(df_wide)} evaluations.")
print(f"Observed Pareto-optimal trial indices: {pareto_trials}")

# Pairwise scatter plots for the 3 objectives, highlighting the Pareto set
fig, axes = plt.subplots(1, 3, figsize=(15, 4), dpi=130)

# 1) pKi vs logS
ax = axes[0]
ax.scatter(df_wide["binding_affinity_pKi"], df_wide["solubility_logS"], fc="None", ec="gray", label="Observed")
ax.scatter(
    df_wide.iloc[pareto_idx_local]["binding_affinity_pKi"],
    df_wide.iloc[pareto_idx_local]["solubility_logS"],
    color="#0033FF",
    label="Pareto (observed)",
)
ax.set_xlabel("binding_affinity_pKi (higher is better)")
ax.set_ylabel("solubility_logS (higher is better)")
ax.grid(True, alpha=0.2)
ax.legend()

# 2) pKi vs LD50
ax = axes[1]
ax.scatter(df_wide["binding_affinity_pKi"], df_wide["toxicity_LD50"], fc="None", ec="gray", label="Observed")
ax.scatter(
    df_wide.iloc[pareto_idx_local]["binding_affinity_pKi"],
    df_wide.iloc[pareto_idx_local]["toxicity_LD50"],
    color="#0033FF",
    label="Pareto (observed)",
)
ax.set_xlabel("binding_affinity_pKi (higher is better)")
ax.set_ylabel("toxicity_LD50 mg/kg (lower is better)")
ax.grid(True, alpha=0.2)
ax.legend()

# 3) logS vs LD50
ax = axes[2]
ax.scatter(df_wide["solubility_logS"], df_wide["toxicity_LD50"], fc="None", ec="gray", label="Observed")
ax.scatter(
    df_wide.iloc[pareto_idx_local]["solubility_logS"],
    df_wide.iloc[pareto_idx_local]["toxicity_LD50"],
    color="#0033FF",
    label="Pareto (observed)",
)
ax.set_xlabel("solubility_logS (higher is better)")
ax.set_ylabel("toxicity_LD50 mg/kg (lower is better)")
ax.grid(True, alpha=0.2)
ax.legend()

plt.tight_layout()
plt.show()