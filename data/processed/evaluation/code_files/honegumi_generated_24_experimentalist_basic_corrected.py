# Generated by Honegumi (https://arxiv.org/abs/2502.06815)
# %pip install ax-platform==0.4.3 matplotlib
import numpy as np
import pandas as pd
from ax.service.ax_client import AxClient, ObjectiveProperties
import matplotlib.pyplot as plt


obj1_name = "branin"
obj2_name = "branin_swapped"


def branin3_moo(x1, x2, x3):
    y = float(
        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2
        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)
        + 10
    )

    # Contrived way to incorporate x3 into the objective
    y = y * (1 + 0.1 * x1 * x2 * x3)

    # second objective has x1 and x2 swapped
    y2 = float(
        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2
        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)
        + 10
    )

    # Contrived way to incorporate x3 into the second objective
    y2 = y2 * (1 - 0.1 * x1 * x2 * x3)

    return {obj1_name: y, obj2_name: y2}


# Define total for compositional constraint, where x1 + x2 + x3 == total
total = 10.0


ax_client = AxClient()

ax_client.create_experiment(
    parameters=[
        {"name": "x1", "type": "range", "bounds": [0.0, total]},
        {"name": "x2", "type": "range", "bounds": [0.0, total]},
    ],
    objectives={
        obj1_name: ObjectiveProperties(minimize=True),
        obj2_name: ObjectiveProperties(minimize=True),
    },
    parameter_constraints=[
        f"x1 + x2 <= {total}",  # reparameterized compositional constraint, which is a type of sum constraint
    ],
)


for i in range(21):

    parameterization, trial_index = ax_client.get_next_trial()

    # extract parameters
    x1 = parameterization["x1"]
    x2 = parameterization["x2"]
    x3 = total - (x1 + x2)  # composition constraint: x1 + x2 + x3 == total

    results = branin3_moo(x1, x2, x3)
    ax_client.complete_trial(trial_index=trial_index, raw_data=results)
pareto_results = ax_client.get_pareto_optimal_parameters()


# Plot results
objectives = ax_client.objective_names
df = ax_client.get_trials_data_frame()

fig, ax = plt.subplots(figsize=(6, 4), dpi=150)
pareto = ax_client.get_pareto_optimal_parameters(use_model_predictions=False)
pareto_data = [p[1][0] for p in pareto.values()]
pareto = pd.DataFrame(pareto_data).sort_values(objectives[0])

ax.scatter(df[objectives[0]], df[objectives[1]], fc="None", ec="k", label="Observed")
ax.plot(
    pareto[objectives[0]],
    pareto[objectives[1]],
    color="#0033FF",
    lw=2,
    label="Pareto Front",
)
ax.set_xlabel(objectives[0])
ax.set_ylabel(objectives[1])

ax.legend()
plt.show()

# Conductive ink multi-objective optimization with Ax (Meta)
# %pip install ax-platform==0.4.3 matplotlib
import numpy as np
import pandas as pd
from typing import Dict, Tuple, Any

from ax.service.ax_client import AxClient, ObjectiveProperties
import matplotlib.pyplot as plt


# Problem constants
TOTAL_PERCENT = 100.0
RNG = np.random.default_rng(42)

# Objective (metric) names
OBJ_CONDUCTIVITY = "conductivity_S_per_m"
OBJ_PRINTABILITY = "printability_score_1_to_10"


def evaluate_conductive_ink(parameters: Dict[str, float]) -> Dict[str, Tuple[float, Any]]:
    """
    Evaluate a conductive ink formulation defined by component percentages.

    Parameters expected (percent by weight):
      - silver_particles_pct in [40, 70]
      - solvent_pct in [15, 35]
      - binder_pct in [5, 20]
    The additive percentage is computed via the composition constraint:
      - additive_pct = 100 - (silver + solvent + binder), constrained to [2, 10] by linear constraints.

    Returns:
      - conductivity_S_per_m: mean conductivity in S/m (maximize), with unknown SEM (None)
      - printability_score_1_to_10: mean score in [1, 10] (maximize), with unknown SEM (None)

    Note:
      This function provides a realistic synthetic model with stochastic noise.
      Replace internals with lab measurement, simulation, or API call as needed.
    """
    silver = float(parameters["silver_particles_pct"])
    solvent = float(parameters["solvent_pct"])
    binder = float(parameters["binder_pct"])
    additive = TOTAL_PERCENT - (silver + solvent + binder)

    # Safety: due to numeric issues, clamp additive to [2, 10]
    additive = float(np.clip(additive, 2.0, 10.0))

    # Convert to fractions
    s = silver / 100.0
    v = solvent / 100.0
    b = binder / 100.0
    a = additive / 100.0

    # Synthetic conductivity model:
    # - Percolation-like dependence on silver above threshold s_c
    # - Decreases with solvent (less solids) and binder (insulating) content
    # - Additive provides modest enhancement
    s_c = 0.50  # percolation threshold (50%)
    exponent = 1.6
    base_scale = 8.0e5  # scale of conductivity (S/m), typical printed inks << bulk Ag

    if s <= s_c:
        sigma = base_scale * 1e-3 * (s / s_c) ** 3  # low conduction below threshold
    else:
        sigma = base_scale * (s - s_c) ** exponent

    # Penalize high solvent and binder; modest boost from additive
    solids_factor = np.exp(-4.0 * v)  # less solvent (v) -> higher factor
    binder_penalty = (1.0 - 0.85 * b)  # binder is insulating; cap penalty magnitude
    additive_boost = 1.0 + 0.8 * a * np.exp(-20.0 * (a - 0.05) ** 2)  # best near 5% additive

    conductivity = sigma * solids_factor * binder_penalty * additive_boost
    conductivity = max(conductivity, 0.0)

    # Add multiplicative log-normal noise (~5% CV)
    noise_sigma = 0.05
    conductivity *= float(RNG.lognormal(mean=0.0, sigma=noise_sigma))

    # Synthetic printability model:
    # - Gaussian preferences around target solvent, binder, additive
    # - Too much silver can hurt printability (viscosity/spreading)
    target_solvent = 0.25
    target_binder = 0.12
    target_additive = 0.06
    target_silver = 0.58

    solvent_term = ((v - target_solvent) / 0.06) ** 2
    binder_term = ((b - target_binder) / 0.05) ** 2
    additive_term = ((a - target_additive) / 0.03) ** 2
    silver_term = ((s - target_silver) / 0.06) ** 2

    base_score = 10.0 * np.exp(-0.5 * (solvent_term + binder_term + additive_term + 0.5 * silver_term))
    # Small penalties for extremes
    extreme_penalty = np.exp(-2.0 * max(0.0, s - 0.65)) * np.exp(-2.0 * max(0.0, v - 0.30))
    printability = base_score * extreme_penalty

    # Add additive Gaussian noise (sd ~0.25)
    printability += float(RNG.normal(loc=0.0, scale=0.25))
    printability = float(np.clip(printability, 1.0, 10.0))

    # Return metrics with unknown SEM (None) to let Ax infer noise
    return {
        OBJ_CONDUCTIVITY: (float(conductivity), None),
        OBJ_PRINTABILITY: (float(printability), None),
    }


# Create and configure the Ax client
ax_client = AxClient()

ax_client.create_experiment(
    name="conductive_ink_multiobjective_optimization",
    parameters=[
        {
            "name": "silver_particles_pct",
            "type": "range",
            "bounds": [40.0, 70.0],
        },
        {
            "name": "solvent_pct",
            "type": "range",
            "bounds": [15.0, 35.0],
        },
        {
            "name": "binder_pct",
            "type": "range",
            "bounds": [5.0, 20.0],
        },
        # additive_pct is computed from composition constraint (not an explicit parameter)
    ],
    objectives={
        OBJ_CONDUCTIVITY: ObjectiveProperties(minimize=False),
        OBJ_PRINTABILITY: ObjectiveProperties(minimize=False),
    },
    # Linear constraints to enforce additive_pct = 100 - (silver + solvent + binder) in [2, 10]
    parameter_constraints=[
        "silver_particles_pct + solvent_pct + binder_pct >= 90.0",
        "silver_particles_pct + solvent_pct + binder_pct <= 98.0",
    ],
)

# Run optimization for the budgeted number of trials
N_TRIALS = 45
for _ in range(N_TRIALS):
    params, trial_index = ax_client.get_next_trial()
    # Evaluate locally; replace with lab workflow or simulation as needed
    results = evaluate_conductive_ink(params)
    ax_client.complete_trial(trial_index=trial_index, raw_data=results)

# Retrieve Pareto-optimal set (based on observed data)
pareto = ax_client.get_pareto_optimal_parameters(use_model_predictions=False)

# Convert Pareto results to DataFrame for inspection
pareto_rows = []
for arm_name, (param_dict, metrics_dict) in pareto.items():
    row = {
        "arm_name": arm_name,
        "silver_particles_pct": param_dict.get("silver_particles_pct"),
        "solvent_pct": param_dict.get("solvent_pct"),
        "binder_pct": param_dict.get("binder_pct"),
    }
    additive_pct = TOTAL_PERCENT - (
        row["silver_particles_pct"] + row["solvent_pct"] + row["binder_pct"]
    )
    row["additive_pct"] = additive_pct
    # Extract metric means
    row[OBJ_CONDUCTIVITY] = (
        metrics_dict[OBJ_CONDUCTIVITY][0]
        if isinstance(metrics_dict[OBJ_CONDUCTIVITY], tuple)
        else metrics_dict[OBJ_CONDUCTIVITY]
    )
    row[OBJ_PRINTABILITY] = (
        metrics_dict[OBJ_PRINTABILITY][0]
        if isinstance(metrics_dict[OBJ_PRINTABILITY], tuple)
        else metrics_dict[OBJ_PRINTABILITY]
    )
    pareto_rows.append(row)

pareto_df = pd.DataFrame(pareto_rows)

# Plot observed points and Pareto frontier
objectives = ax_client.objective_names
df = ax_client.get_trials_data_frame()

fig, ax = plt.subplots(figsize=(7, 5), dpi=140)
ax.scatter(
    df[objectives[0]],
    df[objectives[1]],
    fc="None",
    ec="k",
    alpha=0.6,
    label="Observed",
)
if not pareto_df.empty:
    pareto_df_sorted = pareto_df.sort_values(by=objectives[0])
    ax.plot(
        pareto_df_sorted[objectives[0]],
        pareto_df_sorted[objectives[1]],
        color="#0033FF",
        lw=2,
        label="Pareto Front",
    )
ax.set_xlabel(objectives[0].replace("_", " "))
ax.set_ylabel(objectives[1].replace("_", " "))
ax.set_title("Conductive Ink Optimization: Observations and Pareto Front")
ax.legend()
plt.tight_layout()
plt.show()

# Print top-5 Pareto candidates by conductivity and printability for quick inspection
if not pareto_df.empty:
    print("\nTop 5 Pareto candidates by conductivity:")
    print(
        pareto_df.sort_values(by=OBJ_CONDUCTIVITY, ascending=False)
        .head(5)
        .reset_index(drop=True)
    )
    print("\nTop 5 Pareto candidates by printability:")
    print(
        pareto_df.sort_values(by=OBJ_PRINTABILITY, ascending=False)
        .head(5)
        .reset_index(drop=True)
    )