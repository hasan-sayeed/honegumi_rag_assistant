# Generated by Honegumi (https://arxiv.org/abs/2502.06815)
# %pip install ax-platform==0.4.3 matplotlib
import numpy as np
import pandas as pd
from ax.service.ax_client import AxClient, ObjectiveProperties
import matplotlib.pyplot as plt


obj1_name = "branin"
obj2_name = "branin_swapped"


def branin_moo(x1, x2):
    y = float(
        (x2 - 5.1 / (4 * np.pi**2) * x1**2 + 5.0 / np.pi * x1 - 6.0) ** 2
        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x1)
        + 10
    )

    # second objective has x1 and x2 swapped
    y2 = float(
        (x1 - 5.1 / (4 * np.pi**2) * x2**2 + 5.0 / np.pi * x2 - 6.0) ** 2
        + 10 * (1 - 1.0 / (8 * np.pi)) * np.cos(x2)
        + 10
    )

    return {obj1_name: y, obj2_name: y2}


ax_client = AxClient()

ax_client.create_experiment(
    parameters=[
        {"name": "x1", "type": "range", "bounds": [-5.0, 10.0]},
        {"name": "x2", "type": "range", "bounds": [0.0, 10.0]},
    ],
    objectives={
        obj1_name: ObjectiveProperties(minimize=True),
        obj2_name: ObjectiveProperties(minimize=True),
    },
)


for i in range(19):

    parameterization, trial_index = ax_client.get_next_trial()

    # extract parameters
    x1 = parameterization["x1"]
    x2 = parameterization["x2"]

    results = branin_moo(x1, x2)
    ax_client.complete_trial(trial_index=trial_index, raw_data=results)
pareto_results = ax_client.get_pareto_optimal_parameters()


# Plot results
objectives = ax_client.objective_names
df = ax_client.get_trials_data_frame()

fig, ax = plt.subplots(figsize=(6, 4), dpi=150)
pareto = ax_client.get_pareto_optimal_parameters(use_model_predictions=False)
pareto_data = [p[1][0] for p in pareto.values()]
pareto = pd.DataFrame(pareto_data).sort_values(objectives[0])

ax.scatter(df[objectives[0]], df[objectives[1]], fc="None", ec="k", label="Observed")
ax.plot(
    pareto[objectives[0]],
    pareto[objectives[1]],
    color="#0033FF",
    lw=2,
    label="Pareto Front",
)
ax.set_xlabel(objectives[0])
ax.set_ylabel(objectives[1])

ax.legend()
plt.show()

# Drug candidate optimization with Ax (Multi-objective: pKi ↑, logS ↑, LD50 ↓)
# %pip install ax-platform==0.4.3 matplotlib

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from typing import Dict, Tuple

from ax.service.ax_client import AxClient, ObjectiveProperties


# Objective metric names (domain-specific)
BINDING_PKI = "binding (pKi)"          # maximize
SOLUBILITY_LOGS = "solubility (log S)" # maximize
TOXICITY_LD50 = "toxicity (LD50)"      # minimize per problem statement


def evaluate_molecule(parameters: Dict[str, float]) -> Dict[str, Tuple[float, float]]:
    """
    Simulated evaluation function for a small-molecule drug candidate.

    Inputs (parameterization):
      - MW   : molecular weight in g/mol (continuous: 180–500)
      - LogP : lipophilicity (continuous: 0–5)
      - TPSA : topological polar surface area in Å^2 (continuous: 20–140)
      - HBD  : hydrogen bond donors (continuous proxy: 0–5)
      - HBA  : hydrogen bond acceptors (continuous proxy: 0–10)

    Outputs (metrics):
      - binding (pKi): higher is better (simulate with smooth, physically-inspired heuristics)
      - solubility (log S): higher is better (log mol/L)
      - toxicity (LD50): lower is better per problem statement; units mg/kg (note: in toxicology, higher LD50 implies lower toxicity)

    Returns a dict mapping metric names to (mean, SEM). SEM=None indicates unknown noise level.
    """
    MW = float(parameters["MW"])
    LogP = float(parameters["LogP"])
    TPSA = float(parameters["TPSA"])
    HBD = float(parameters["HBD"])
    HBA = float(parameters["HBA"])

    rng = np.random.default_rng()

    # Helper: Gaussian bump centered at mu with width sigma
    def bump(x, mu, sigma):
        return float(np.exp(-0.5 * ((x - mu) / sigma) ** 2))

    # 1) Binding affinity surrogate (pKi)
    # Favor moderate MW (~350), LogP (~2.5), TPSA (~60), modest HBD (~1.5), HBA (~4)
    mw_term = bump(MW, 350.0, 80.0)
    logp_term = bump(LogP, 2.5, 1.2)
    tpsa_term = bump(TPSA, 60.0, 25.0)
    hbd_term = bump(HBD, 1.5, 1.0)
    hba_term = bump(HBA, 4.0, 2.0)
    binding_core = 6.0 + 2.8 * (0.35 * mw_term + 0.35 * logp_term + 0.15 * tpsa_term + 0.075 * hbd_term + 0.075 * hba_term)
    # Mild penalty for very high TPSA (permeability issues) and extreme MW
    binding_penalty = 0.2 * ((max(TPSA - 100.0, 0.0) / 40.0) + (max(MW - 450.0, 0.0) / 100.0))
    pKi = binding_core - binding_penalty
    pKi += rng.normal(0.0, 0.1)  # measurement noise
    pKi = float(np.clip(pKi, 4.0, 12.0))

    # 2) Aqueous solubility surrogate (log S, log10 mol/L)
    # Improves with lower LogP, lower MW, higher TPSA, modest HBD/HBA
    logS = (
        -0.5
        - 1.1 * LogP
        - 0.0030 * (MW - 180.0)
        + 0.010 * (TPSA - 20.0)
        + 0.10 * bump(HBD, 1.0, 0.8)
        + 0.06 * bump(HBA, 3.0, 1.5)
        - 0.0006 * max(0.0, MW - 350.0) * max(0.0, LogP - 2.0)  # interaction penalty
    )
    logS += rng.normal(0.0, 0.15)
    logS = float(np.clip(logS, -8.0, 1.0))

    # 3) Toxicity surrogate (LD50 mg/kg) — per problem statement: minimize LD50
    # Heuristic: higher LogP and very high MW reduce LD50 (more toxic), higher TPSA increases LD50 (less toxic),
    # extreme HBA may reduce LD50, moderate HBD may increase LD50 slightly.
    base_ld50 = 1200.0
    ld50 = (
        base_ld50
        - 220.0 * (LogP ** 1.3)
        - 1.2 * max(0.0, MW - 300.0)
        + 6.0 * TPSA
        + 80.0 * bump(HBD, 1.0, 0.7)
        - 35.0 * max(0.0, HBA - 6.0)
    )
    ld50 += rng.normal(0.0, 60.0)
    ld50 = float(np.clip(ld50, 5.0, 5000.0))

    # Return means with unknown SEM (None => Ax will infer noise)
    return {
        BINDING_PKI: (pKi, None),
        SOLUBILITY_LOGS: (logS, None),
        TOXICITY_LD50: (ld50, None),
    }


def _compute_nondominated_mask(values: np.ndarray, minimize: np.ndarray) -> np.ndarray:
    """
    Compute Pareto non-dominated mask for M objectives.
    values: shape (N, M)
    minimize: boolean array shape (M,), True if that objective is to be minimized.
    Returns: boolean mask shape (N,), True for non-dominated points.
    """
    # Convert to minimization problem
    conv = values.copy()
    for j in range(values.shape[1]):
        if not minimize[j]:
            conv[:, j] = -conv[:, j]
    N = conv.shape[0]
    is_dominated = np.zeros(N, dtype=bool)
    for i in range(N):
        if is_dominated[i]:
            continue
        vi = conv[i]
        # A point j dominates i if vj <= vi in all dims and vj < vi in at least one dim
        dominates_i = np.all(conv <= vi + 1e-12, axis=1) & np.any(conv < vi - 1e-12, axis=1)
        dominates_i[i] = False
        if np.any(dominates_i):
            is_dominated[i] = True
    return ~is_dominated


def main():
    rng = np.random.default_rng(1234)

    ax_client = AxClient()
    ax_client.create_experiment(
        name="drug_candidate_multi_objective_optimization",
        parameters=[
            {"name": "MW", "type": "range", "bounds": [180.0, 500.0]},   # g/mol
            {"name": "LogP", "type": "range", "bounds": [0.0, 5.0]},     # unitless
            {"name": "TPSA", "type": "range", "bounds": [20.0, 140.0]},  # Å^2
            {"name": "HBD", "type": "range", "bounds": [0.0, 5.0]},      # count (treated continuous)
            {"name": "HBA", "type": "range", "bounds": [0.0, 10.0]},     # count (treated continuous)
        ],
        objectives={
            BINDING_PKI: ObjectiveProperties(minimize=False),  # maximize pKi
            SOLUBILITY_LOGS: ObjectiveProperties(minimize=False),  # maximize log S
            TOXICITY_LD50: ObjectiveProperties(minimize=True),  # per problem statement
        },
    )

    NUM_TRIALS = 50  # budget

    for _ in range(NUM_TRIALS):
        parameterization, trial_index = ax_client.get_next_trial()
        results = evaluate_molecule(parameterization)
        ax_client.complete_trial(trial_index=trial_index, raw_data=results)

    # Retrieve results as DataFrame
    df = ax_client.get_trials_data_frame()

    # The trials data frame should include metric columns with names equal to our objective names.
    # Build a compact matrix of outcomes with one row per completed trial.
    # If multiple rows per trial exist, pivot to wide format using metric names.
    if {"trial_index", "metric_name", "mean"}.issubset(df.columns):
        # Long format -> pivot
        outcomes_wide = df.pivot_table(
            index="trial_index",
            columns="metric_name",
            values="mean",
            aggfunc="last",
        ).reset_index()
    else:
        outcomes_wide = df.copy()

    # Ensure all three objective columns are present
    needed_cols = [BINDING_PKI, SOLUBILITY_LOGS, TOXICITY_LD50]
    outcomes_wide = outcomes_wide[[c for c in needed_cols if c in outcomes_wide.columns]]

    # Convert to numpy for Pareto filtering across all three objectives
    vals = outcomes_wide[needed_cols].to_numpy(dtype=float)
    minimize_flags = np.array([False, False, True], dtype=bool)
    nd_mask = _compute_nondominated_mask(vals, minimize=minimize_flags)

    # Pairwise scatter plots for the three objectives with Pareto-optimal points highlighted
    pairs = [
        (BINDING_PKI, SOLUBILITY_LOGS),
        (BINDING_PKI, TOXICITY_LD50),
        (SOLUBILITY_LOGS, TOXICITY_LD50),
    ]
    fig, axes = plt.subplots(1, 3, figsize=(15, 4), dpi=150)
    for ax, (x_name, y_name) in zip(axes, pairs):
        if x_name not in outcomes_wide.columns or y_name not in outcomes_wide.columns:
            ax.set_visible(False)
            continue
        x = outcomes_wide[x_name].to_numpy()
        y = outcomes_wide[y_name].to_numpy()
        ax.scatter(x, y, fc="None", ec="gray", alpha=0.7, label="Observed")
        ax.scatter(x[nd_mask], y[nd_mask], c="#0033FF", s=20, label="Pareto-optimal")
        ax.set_xlabel(x_name)
        ax.set_ylabel(y_name)
        ax.legend(loc="best", fontsize=8)
        ax.grid(True, alpha=0.2)
    plt.tight_layout()
    plt.show()


if __name__ == "__main__":
    main()